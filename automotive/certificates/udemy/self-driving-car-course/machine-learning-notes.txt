/////////////////////////////////
////Section 6 : The Perceptron //
////////////////////////////////

# Neural network (NN)
- inspired from biological neural
- it simulates the way the human (brain) learns

## The perceptron : 
    => 1 input layer
        => input nodes : x1*w1 + x2*w2 ...+ b
            where : 
            x : input signals
            b : bias 
            w : weights
    => Neuron 
        => Summation function
        => activation function (step : 0/1) 

    => 1 output layer 

- The multilayer perceptron forms fully connected NN 
    => 1 input layer 
    => multiple hidden layers
    => Neuron 
        => Summation function
        => activation functions (step, tanh, sigmoid, RELU...)

    => 1 output layer

## MACHINE LEARNING ##

- ML Model types
    - Supervised learning (SP)
    - UnSupervised learning (NSP)
    - reinforcement learning (RL)

=> Supervised learning (SP) algorithms/model
    - Regression
        => Linear 
        => Non-Linear 
    - Classification 
        => Linear model
        => Non-Linear 

//// Regression ////
- https://github.com/afondiel/research-notes/tree/master/ai/ml-notes
- https://github.com/afondiel/research-notes/blob/master/datascience-notes/certificates/coursera/ibm/ds-ibm-notes.txt
    => course 7 - W4 : Model dev
    => course 9 - W2 : Regression 

//// Classification ////
- https://github.com/afondiel/research-notes/tree/master/ai/ml-notes
- https://github.com/afondiel/research-notes/blob/master/datascience-notes/certificates/coursera/ibm/ds-ibm-notes.txt
    => Course 9 - W3 : Classification

### TRAINING/FITTING 

/!\ The characteristics of a Great Model : 
    => low error
    => high accuracy 


=> learning/working Technics : 
- Forward propagation : input data is fed in the forward direction through the network 
    => feed forward => input + hidden + output
- Back propagation : allows NN figure out patterns that are convoluted complex for human to extract
    => feed forward + calculate error + back propagation


#### Cost/Loss functions

* Regression 

- Most common Model evaluation metrics :
	=> MAE : Mean Absolute Error 
+--------------------------+
|MAE = 1/n*Sum(|yi - ^yi|) |
+--------------------------+
	=> MSE : Mean Squared error 
+--------------------------+
|MSE = 1/n*Sum(yi - ^yi)2  |
+--------------------------+
	=> RMSE : Root Mean Squared error 
+--------------------------+
|RMSE^2 = 1/n*Sum(yi - ^yi)|
+--------------------------+

	=> RAE : Relative Absolute Error/Residual sum of square 
+---------------------------+
|RAE = n*MAE/Sum(|yi - ÿi|) | where ÿ : mean of y 
+---------------------------+

	=> RSE : Relative Squared error : (very similar to MAE, is used for Normalization) => used to calculate R^2
+--------------------------------------+
|RSE = Sum(yi - ^yi)^2 / Sum(yi - ÿ)^2 |
+--------------------------------------+

- R squared  : represents how close the data values are to the fitted regression line 
=> the more R^2 is higher the more the model fitted the data  

[R^2 = 1 - RSE]  

## Classification 
- Cross-entropy loss (error calculation)


#### Optimization functions
    => Least Squares
    => Gradient Descent

#### Activation functions 
    => step () : 
        => 0 if score < 0
        => 1 if score >= 0 
    => sigmoid
    => tanh
    => SoftMax
    => RELU
    ...



# References 
The perceptron : 
https://en.wikipedia.org/wiki/Perceptron
Neural Network
https://www.youtube.com/watch?v=aircAruvnKk
SP vs USP vs RL
https://www.aitude.com/supervised-vs-unsupervised-vs-reinforcement/
