# Antropic Research Notes

## Overview

Anthropic AI safety platform is a term that refers to the platform developed by Anthropic, an AI safety and research company based in San Francisco. The platform consists of the following components:

- **Claude**, an AI assistant that can perform various tasks such as searching, generating answers, automating workflows, coding, and processing text in natural conversations.
- **Constitutional AI**, a technique that allows users to specify and enforce constraints on the behavior and objectives of AI systems.
- **Frontier models**, a new class of models that can learn from multiple sources of data and feedback, and adapt to new domains and tasks.


The platform aims to build reliable, beneficial, and interpretable AI systems that can be aligned with human values, steered by human feedback, and explained by human language. 

The platform also leverages the latest advances in large language models (LLMs) and retrieval-augmented generation (RAG) to improve the performance and scalability of AI applications. 

The platform is compatible with popular frameworks such as:
  - Hugging Face Transformers 
  - PyTorch
  - ...

## References

- [Anthropic \ Core Views on AI Safety: When, Why, What, and How](https://www.anthropic.com/index/core-views-on-ai-safety)
- [Anthropic \ Anthropic Partners with Google Cloud](https://www.anthropic.com/index/anthropic-partners-with-google-cloud)
- [Anthropic \ Home](https://www.anthropic.com/)
- [Anthropic’s new policy takes aim at ‘catastrophic’ AI risks](https://venturebeat.com/ai/anthropics-new-policy-takes-aim-at-catastrophic-ai-risks/)
- [AI research company Anthropic raises $580M in funding](https://siliconangle.com/2022/04/29/ai-research-company-anthropic-raises-580m-funding/)
- [linkedin.com/anthropicresearch](https://www.linkedin.com/company/anthropicresearch)


